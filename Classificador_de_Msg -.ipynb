{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "babe64ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\estcgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed2583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'na', 'não', 'nas', 'nem', 'no', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 'são', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'seu', 'seus', 'só', 'somos', 'sou', 'sua', 'suas', 'também', 'te', 'tem', 'tém', 'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'terá', 'terão', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tu', 'tua', 'tuas', 'um', 'uma', 'você', 'vocês', 'vos', 'vou', 'tão']\n",
      "[(['trabalh', 'agrad'], 'alegria'), (['gost', 'fic', 'aconcheg'], 'alegria'), (['fiz', 'ades', 'curs', 'hoj'], 'alegria'), (['admir', 'muit'], 'alegria'), (['ador'], 'alegria'), (['ador', 'cabel', 'maci'], 'alegria'), (['ador', 'cor', 'olh'], 'alegria'), (['som', 'am', 'outr'], 'alegria'), (['sint', 'grand', 'afe'], 'alegria'), (['quer', 'agrad', 'filh'], 'alegria'), (['sint', 'complet', 'am'], 'alegria'), (['amo'], 'alegria'), (['grand', 'alivi'], 'alegria'), (['dor', 'ameniz', 'final'], 'alegria'), (['ach', 'apaixon'], 'alegria'), (['am', 'maravilh'], 'alegria'), (['sent', 'anim'], 'alegria'), (['sint', 'bem', 'hoj'], 'alegria'), (['lu', 'bel'], 'alegria'), (['dia', 'bonit'], 'alegria'), (['afortun'], 'alegria'), (['maravilh', 'mund'], 'alegria'), (['receb', 'car', 'hoj', 'coleg'], 'alegria'), (['sent', 'reconfort', 'hoj'], 'alegria'), (['bom', 'amig'], 'alegria'), (['cont', 'result', 'test'], 'alegria'), (['pint', 'bem', 'brilh'], 'alegria'), (['águ', 'abundanc'], 'alegria'), (['roup', 'delic'], 'alegria'), (['grand', 'comedi'], 'alegria'), (['bondad', 'vir', 'aqu'], 'alegria'), (['am', 'lind'], 'alegria'), (['amizad', 'vai', 'dur', 'sempr'], 'alegria'), (['eufór', 'notic'], 'alegria'), (['real', 'fiel', 'mim'], 'alegria'), (['dar', 'grand', 'fest', 'comemor', 'aniversári'], 'alegria'), (['graç', 'deu', 'enxerg', 'cert'], 'alegria'), (['melhor', 'escolh', 'tod'], 'alegria'), (['incr', 'bel'], 'alegria'), (['engraç', 'tent', 'explic'], 'alegria'), (['emocion', 'nest', 'lug'], 'alegria'), (['cativ', 'olh'], 'alegria'), (['louc', 'apaixon'], 'alegria'), (['nunc', 'duvid'], 'alegria'), (['rode', 'abraç'], 'alegria'), (['vej', 'estrel', 'caminh'], 'alegria'), (['sint', 'sol', 'sempr', 'pert'], 'alegria'), (['sorr', 'orelh', 'orelh'], 'alegria'), (['val', 'pen'], 'alegria'), (['final', 'coloc', 'am', 'prim', 'lug'], 'alegria'), (['danç', 'noit', 'adentr'], 'alegria'), (['am', 'brilh'], 'alegria'), (['toq', 'muit', 'coraçã', 'dur', 'caminh'], 'alegria'), (['amig', 'companh'], 'alegria'), (['traz', 'volt', 'vid'], 'alegria'), (['sonh', 'doc'], 'alegria'), (['ador', 'doc', 'frut'], 'alegria'), (['suc', 'favorit'], 'alegria'), (['agradec', 'ajud'], 'alegria'), (['enorm', 'praz', 'ter', 'equip'], 'alegria'), (['trabalh', 'equip', 'melhor'], 'alegria'), (['sint', 'flutu', 'ar'], 'alegria'), (['bris', 'agrad', 'hoj'], 'alegria'), (['ótim', 'compat'], 'alegria'), (['compat', 'outr'], 'alegria'), (['órg', 'compat', 'paci'], 'alegria'), (['cont', 'aceit', 'faculdad'], 'alegria'), (['aprov', 'exam'], 'alegria'), (['benefici', 'empr'], 'alegria'), (['cativ'], 'alegria'), (['cont', 'apoi'], 'alegria'), (['lug', 'confort'], 'alegria'), (['bom', 'quent', 'nest', 'fri'], 'alegria'), (['elogi', 'nunc', 'demal'], 'alegria'), (['cham', 'comemor'], 'alegria'), (['desej', 'presenç', 'apresent'], 'alegria'), (['grat'], 'alegria'), (['dedic', 'naquil', 'faç'], 'alegria'), (['complet', 'apaixon'], 'alegria'), (['vam', 'agit', 'noit'], 'alegria'), (['signif', 'mim'], 'alegria'), (['vam', 'agir', 'preconceit', 'julg'], 'alegria'), (['final', 'complet', 'coleção,', 'maravilh'], 'alegria'), (['rainh'], 'alegria'), (['satisf', 'anunci', 'venc', 'jog'], 'alegria'), (['atr', 'facil'], 'alegria'), (['rapaz', 'extrem', 'atra'], 'alegria'), (['sinto-m', 'viv'], 'alegria'), (['sinto-m', 'paz'], 'alegria'), (['tend', 'lucr'], 'alegria'), (['bem', 'tud', 'ord', 'agor'], 'alegria'), (['pod', 'arrum', 'empreg', 'junt'], 'alegria'), (['arrum', 'terminada,', 'alívi'], 'alegria'), (['cânc', 'benign'], 'alegria'), (['am', 'abund'], 'alegria'), (['vam', 'carid', 'natal'], 'alegria'), (['tod', 'charm', 'irá', 'atra', 'tod'], 'alegria'), (['charm', 'quer'], 'alegria'), (['quer', 'amig'], 'alegria'), (['cuidad', 'sent'], 'alegria'), (['comov', 'tamanh', 'caridad'], 'alegria'), (['chá', 'quent', 'reconfort'], 'alegria'), (['alegr', 'ter', 'aqu'], 'alegria'), (['vam', 'aplaud', 'venc'], 'alegria'), (['palm', 'aniversari'], 'alegria'), (['desej', 'tud', 'bom'], 'alegria'), (['hor', 'apreci', 'bom', 'vinh'], 'alegria'), (['apreci', 'presenç', 'escol'], 'alegria'), (['ansei', 'próx', 'trabalh'], 'alegria'), (['maravilh', 'jog', 'amist'], 'alegria'), (['ótim', 'ânim', 'apazigu'], 'alegria'), (['concretiz', 'final', 'sonh'], 'alegria'), (['imploro,', 'matem!'], 'medo'), (['cert', 'perigoso?'], 'medo'), (['cert', 'segur'], 'medo'), (['corr', 'pra', 'peg'], 'medo'), (['socorro!', 'quer', 'roub', 'doces!'], 'medo'), (['car', 'persegu'], 'medo'), (['entr', 'lá,', 'lug', 'perig'], 'medo'), (['lug', 'continu', 'assust'], 'medo'), (['selv', 'muit', 'animal', 'perig'], 'medo'), (['avanc', 'cautel'], 'medo'), (['lug', 'silenci', 'mais,', 'cuidado!'], 'medo'), (['favor,', 'deixe-m', 'viver!'], 'medo'), (['fic', 'mes', 'tir', 'not', 'baix'], 'medo'), (['parec', 'olh', 'vigi'], 'medo'), (['tem', 'sentenç', 'juiz', 'poss', 'nega'], 'medo'), (['miss', 'arrisc'], 'medo'), (['salvem-s', 'puder!'], 'medo'), (['plan', 'pod', 'descobert'], 'medo'), (['culpa,', 'jur'], 'medo'), (['tom', 'cuid', 'lobisom'], 'medo'), (['achar,', 'vai', 'descobr', 'verdad'], 'medo'), (['deus,', 'desapareceu!'], 'medo'), (['tom', 'vej', 'daqui!'], 'medo'), (['mantenh', 'segredo,', 'descobr', 'est', 'ferr'], 'medo'), (['favor,', 'soltem,', 'inoc'], 'medo'), (['ouv', 'pass', 'atrás', 'mim'], 'medo'), (['ped', 'socorro!'], 'medo'), (['cuid', 'curv', 'estr'], 'medo'), (['sei', 'não,', 'parec', 'perig'], 'medo'), (['trem', 'medo!'], 'medo'), (['socorro,', 'cair!'], 'medo'), (['ate', 'florest', 'negra,', 'perig'], 'medo'), (['ouç', 'pass', 'direç'], 'medo'), (['ach', 'arrisc'], 'medo'), (['vam', 'voltar,', 'perig'], 'medo'), (['fuja,', 'acab', 'mort'], 'medo'), (['recei', 'livr', 'dest', 'situ'], 'medo'), (['socorro!', 'armado!'], 'medo'), (['ei', 'cuidado,', 'vai', 'bat', 'poste!'], 'medo'), (['socorro,', 'afund'], 'medo'), (['serio,', 'cuid', 'arma!'], 'medo'), (['tub', 'atacando!'], 'medo'), (['sint', 'arrepi', 'fic', 'so', 'escur'], 'medo'), (['calma,', 'dinh'], 'medo'), (['ach', 'send', 'engan'], 'medo'), (['ligeiro,', 'fug', 'depress'], 'medo'), (['crocodil', 'selv', 'vind', 'cá'], 'medo'), (['fic', 'quiet', 'vão', 'ach'], 'medo'), (['fuja!', 'tigr', 'parec', 'famint'], 'medo'), (['saída,', 'precis', 'milagr'], 'medo'), (['tir', 'mim!', 'socorro!'], 'medo'), (['sei', 'nadar,', 'afogar!'], 'medo'), (['cert', 'segur'], 'medo'), (['apanh', 'pal', 'ver', 'boletim'], 'medo'), (['consig', 'sair', 'daqui!'], 'medo'), (['sair', 'tarde,', 'pod', 'assalt'], 'medo'), (['deix', 'favor!'], 'medo'), (['espere,', 'pod', 'larg', 'aqu', 'so'], 'medo'), (['tem', 'seguranç'], 'medo'), (['entreg', 'dinheiro,', 'favor', 'mate!'], 'medo'), (['vai', 'lev', 'tod', 'dinh'], 'medo'), (['dirij', 'rápid', 'assim'], 'medo'), (['descobriram,', 'irã', 'prender!'], 'medo'), (['esper', 'faç', 'nenhum', 'mal'], 'medo'), (['afogar,', 'ajud', 'sair', 'águ'], 'medo'), (['est', 'salv', 'aqu'], 'medo'), (['quer', 'pens', 'pod', 'acontec'], 'medo'), (['ness', 'cidad', 'desgr', 'atrás', 'outr'], 'medo'), (['algu', 'ligando,', 'assust'], 'medo'), (['remedio,', 'mat'], 'medo'), (['confi', 'nele,', 'ter', 'cautel'], 'medo'), (['muit', 'cautel'], 'medo'), (['descoberto,', 'deu'], 'medo'), (['recei', 'ir'], 'medo'), (['noit', 'perig'], 'medo'), (['estremec', 'cas'], 'medo'), (['olh', 'criat', 'mov', 'monstruos'], 'medo'), (['agüent', 'suspens'], 'medo'), (['afug', 'cão'], 'medo'), (['choc', 'amedront', 'assassinat', 'brut'], 'medo'), (['precis', 'afugent', 'ímpet', 'med', 'infern'], 'medo'), (['polít', 'us', 'forç', 'afugent', 'amedront', 'pov'], 'medo'), (['obje', 'diss', 'apen', 'amedront'], 'medo'), (['apav'], 'medo')]\n",
      "['trabalh', 'agrad', 'gost', 'fic', 'aconcheg', 'fiz', 'ades', 'curs', 'hoj', 'admir', 'muit', 'ador', 'ador', 'cabel', 'maci', 'ador', 'cor', 'olh', 'som', 'am', 'outr', 'sint', 'grand', 'afe', 'quer', 'agrad', 'filh', 'sint', 'complet', 'am', 'amo', 'grand', 'alivi', 'dor', 'ameniz', 'final', 'ach', 'apaixon', 'am', 'maravilh', 'sent', 'anim', 'sint', 'bem', 'hoj', 'lu', 'bel', 'dia', 'bonit', 'afortun', 'maravilh', 'mund', 'receb', 'car', 'hoj', 'coleg', 'sent', 'reconfort', 'hoj', 'bom', 'amig', 'cont', 'result', 'test', 'pint', 'bem', 'brilh', 'águ', 'abundanc', 'roup', 'delic', 'grand', 'comedi', 'bondad', 'vir', 'aqu', 'am', 'lind', 'amizad', 'vai', 'dur', 'sempr', 'eufór', 'notic', 'real', 'fiel', 'mim', 'dar', 'grand', 'fest', 'comemor', 'aniversári', 'graç', 'deu', 'enxerg', 'cert', 'melhor', 'escolh', 'tod', 'incr', 'bel', 'engraç', 'tent', 'explic', 'emocion', 'nest', 'lug', 'cativ', 'olh', 'louc', 'apaixon', 'nunc', 'duvid', 'rode', 'abraç', 'vej', 'estrel', 'caminh', 'sint', 'sol', 'sempr', 'pert', 'sorr', 'orelh', 'orelh', 'val', 'pen', 'final', 'coloc', 'am', 'prim', 'lug', 'danç', 'noit', 'adentr', 'am', 'brilh', 'toq', 'muit', 'coraçã', 'dur', 'caminh', 'amig', 'companh', 'traz', 'volt', 'vid', 'sonh', 'doc', 'ador', 'doc', 'frut', 'suc', 'favorit', 'agradec', 'ajud', 'enorm', 'praz', 'ter', 'equip', 'trabalh', 'equip', 'melhor', 'sint', 'flutu', 'ar', 'bris', 'agrad', 'hoj', 'ótim', 'compat', 'compat', 'outr', 'órg', 'compat', 'paci', 'cont', 'aceit', 'faculdad', 'aprov', 'exam', 'benefici', 'empr', 'cativ', 'cont', 'apoi', 'lug', 'confort', 'bom', 'quent', 'nest', 'fri', 'elogi', 'nunc', 'demal', 'cham', 'comemor', 'desej', 'presenç', 'apresent', 'grat', 'dedic', 'naquil', 'faç', 'complet', 'apaixon', 'vam', 'agit', 'noit', 'signif', 'mim', 'vam', 'agir', 'preconceit', 'julg', 'final', 'complet', 'coleção,', 'maravilh', 'rainh', 'satisf', 'anunci', 'venc', 'jog', 'atr', 'facil', 'rapaz', 'extrem', 'atra', 'sinto-m', 'viv', 'sinto-m', 'paz', 'tend', 'lucr', 'bem', 'tud', 'ord', 'agor', 'pod', 'arrum', 'empreg', 'junt', 'arrum', 'terminada,', 'alívi', 'cânc', 'benign', 'am', 'abund', 'vam', 'carid', 'natal', 'tod', 'charm', 'irá', 'atra', 'tod', 'charm', 'quer', 'quer', 'amig', 'cuidad', 'sent', 'comov', 'tamanh', 'caridad', 'chá', 'quent', 'reconfort', 'alegr', 'ter', 'aqu', 'vam', 'aplaud', 'venc', 'palm', 'aniversari', 'desej', 'tud', 'bom', 'hor', 'apreci', 'bom', 'vinh', 'apreci', 'presenç', 'escol', 'ansei', 'próx', 'trabalh', 'maravilh', 'jog', 'amist', 'ótim', 'ânim', 'apazigu', 'concretiz', 'final', 'sonh', 'imploro,', 'matem!', 'cert', 'perigoso?', 'cert', 'segur', 'corr', 'pra', 'peg', 'socorro!', 'quer', 'roub', 'doces!', 'car', 'persegu', 'entr', 'lá,', 'lug', 'perig', 'lug', 'continu', 'assust', 'selv', 'muit', 'animal', 'perig', 'avanc', 'cautel', 'lug', 'silenci', 'mais,', 'cuidado!', 'favor,', 'deixe-m', 'viver!', 'fic', 'mes', 'tir', 'not', 'baix', 'parec', 'olh', 'vigi', 'tem', 'sentenç', 'juiz', 'poss', 'nega', 'miss', 'arrisc', 'salvem-s', 'puder!', 'plan', 'pod', 'descobert', 'culpa,', 'jur', 'tom', 'cuid', 'lobisom', 'achar,', 'vai', 'descobr', 'verdad', 'deus,', 'desapareceu!', 'tom', 'vej', 'daqui!', 'mantenh', 'segredo,', 'descobr', 'est', 'ferr', 'favor,', 'soltem,', 'inoc', 'ouv', 'pass', 'atrás', 'mim', 'ped', 'socorro!', 'cuid', 'curv', 'estr', 'sei', 'não,', 'parec', 'perig', 'trem', 'medo!', 'socorro,', 'cair!', 'ate', 'florest', 'negra,', 'perig', 'ouç', 'pass', 'direç', 'ach', 'arrisc', 'vam', 'voltar,', 'perig', 'fuja,', 'acab', 'mort', 'recei', 'livr', 'dest', 'situ', 'socorro!', 'armado!', 'ei', 'cuidado,', 'vai', 'bat', 'poste!', 'socorro,', 'afund', 'serio,', 'cuid', 'arma!', 'tub', 'atacando!', 'sint', 'arrepi', 'fic', 'so', 'escur', 'calma,', 'dinh', 'ach', 'send', 'engan', 'ligeiro,', 'fug', 'depress', 'crocodil', 'selv', 'vind', 'cá', 'fic', 'quiet', 'vão', 'ach', 'fuja!', 'tigr', 'parec', 'famint', 'saída,', 'precis', 'milagr', 'tir', 'mim!', 'socorro!', 'sei', 'nadar,', 'afogar!', 'cert', 'segur', 'apanh', 'pal', 'ver', 'boletim', 'consig', 'sair', 'daqui!', 'sair', 'tarde,', 'pod', 'assalt', 'deix', 'favor!', 'espere,', 'pod', 'larg', 'aqu', 'so', 'tem', 'seguranç', 'entreg', 'dinheiro,', 'favor', 'mate!', 'vai', 'lev', 'tod', 'dinh', 'dirij', 'rápid', 'assim', 'descobriram,', 'irã', 'prender!', 'esper', 'faç', 'nenhum', 'mal', 'afogar,', 'ajud', 'sair', 'águ', 'est', 'salv', 'aqu', 'quer', 'pens', 'pod', 'acontec', 'ness', 'cidad', 'desgr', 'atrás', 'outr', 'algu', 'ligando,', 'assust', 'remedio,', 'mat', 'confi', 'nele,', 'ter', 'cautel', 'muit', 'cautel', 'descoberto,', 'deu', 'recei', 'ir', 'noit', 'perig', 'estremec', 'cas', 'olh', 'criat', 'mov', 'monstruos', 'agüent', 'suspens', 'afug', 'cão', 'choc', 'amedront', 'assassinat', 'brut', 'precis', 'afugent', 'ímpet', 'med', 'infern', 'polít', 'us', 'forç', 'afugent', 'amedront', 'pov', 'obje', 'diss', 'apen', 'amedront', 'apav']\n",
      "[('am', 7), ('sint', 6), ('lug', 6), ('perig', 6), ('hoj', 5), ('quer', 5), ('vam', 5), ('pod', 5), ('fic', 4), ('muit', 4), ('ador', 4), ('olh', 4), ('grand', 4), ('final', 4), ('ach', 4), ('maravilh', 4), ('bom', 4), ('aqu', 4), ('vai', 4), ('cert', 4), ('tod', 4), ('socorro!', 4), ('trabalh', 3), ('agrad', 3), ('outr', 3), ('complet', 3), ('apaixon', 3), ('sent', 3), ('bem', 3), ('amig', 3), ('cont', 3), ('mim', 3), ('noit', 3), ('ter', 3), ('compat', 3), ('cautel', 3), ('parec', 3), ('cuid', 3), ('sair', 3), ('amedront', 3), ('bel', 2), ('car', 2), ('reconfort', 2), ('brilh', 2), ('águ', 2), ('dur', 2), ('sempr', 2), ('comemor', 2), ('deu', 2), ('melhor', 2)]\n",
      "{'trabalh': False, 'agrad': False, 'gost': False, 'fic': False, 'aconcheg': False, 'fiz': False, 'ades': False, 'curs': False, 'hoj': False, 'admir': False, 'muit': False, 'ador': False, 'cabel': False, 'maci': False, 'cor': False, 'olh': False, 'som': False, 'am': True, 'outr': False, 'sint': False, 'grand': False, 'afe': False, 'quer': False, 'filh': False, 'complet': False, 'amo': False, 'alivi': False, 'dor': False, 'ameniz': False, 'final': False, 'ach': False, 'apaixon': False, 'maravilh': False, 'sent': False, 'anim': False, 'bem': False, 'lu': False, 'bel': False, 'dia': True, 'bonit': False, 'afortun': False, 'mund': False, 'receb': False, 'car': False, 'coleg': False, 'reconfort': False, 'bom': False, 'amig': False, 'cont': False, 'result': False, 'test': False, 'pint': False, 'brilh': False, 'águ': False, 'abundanc': False, 'roup': False, 'delic': False, 'comedi': False, 'bondad': False, 'vir': False, 'aqu': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'eufór': False, 'notic': False, 'real': False, 'fiel': False, 'mim': False, 'dar': False, 'fest': False, 'comemor': False, 'aniversári': False, 'graç': False, 'deu': False, 'enxerg': False, 'cert': False, 'melhor': False, 'escolh': False, 'tod': False, 'incr': False, 'engraç': False, 'tent': False, 'explic': False, 'emocion': False, 'nest': False, 'lug': False, 'cativ': False, 'louc': False, 'nunc': False, 'duvid': False, 'rode': False, 'abraç': False, 'vej': False, 'estrel': False, 'caminh': False, 'sol': False, 'pert': False, 'sorr': False, 'orelh': False, 'val': False, 'pen': False, 'coloc': False, 'prim': False, 'danç': False, 'noit': False, 'adentr': False, 'toq': False, 'coraçã': False, 'companh': False, 'traz': False, 'volt': False, 'vid': False, 'sonh': False, 'doc': False, 'frut': False, 'suc': False, 'favorit': False, 'agradec': False, 'ajud': False, 'enorm': False, 'praz': False, 'ter': False, 'equip': False, 'flutu': False, 'ar': False, 'bris': False, 'ótim': False, 'compat': False, 'órg': False, 'paci': False, 'aceit': False, 'faculdad': False, 'aprov': False, 'exam': False, 'benefici': False, 'empr': False, 'apoi': False, 'confort': False, 'quent': False, 'fri': False, 'elogi': False, 'demal': False, 'cham': False, 'desej': False, 'presenç': False, 'apresent': False, 'grat': False, 'dedic': False, 'naquil': False, 'faç': False, 'vam': False, 'agit': False, 'signif': False, 'agir': False, 'preconceit': False, 'julg': False, 'coleção,': False, 'rainh': False, 'satisf': False, 'anunci': False, 'venc': False, 'jog': False, 'atr': False, 'facil': False, 'rapaz': False, 'extrem': False, 'atra': False, 'sinto-m': False, 'viv': False, 'paz': False, 'tend': False, 'lucr': False, 'tud': False, 'ord': False, 'agor': False, 'pod': False, 'arrum': False, 'empreg': False, 'junt': False, 'terminada,': False, 'alívi': False, 'cânc': False, 'benign': False, 'abund': False, 'carid': False, 'natal': False, 'charm': False, 'irá': False, 'cuidad': False, 'comov': False, 'tamanh': False, 'caridad': False, 'chá': False, 'alegr': False, 'aplaud': False, 'palm': False, 'aniversari': False, 'hor': False, 'apreci': False, 'vinh': False, 'escol': False, 'ansei': False, 'próx': False, 'amist': False, 'ânim': False, 'apazigu': False, 'concretiz': False, 'imploro,': False, 'matem!': False, 'perigoso?': False, 'segur': False, 'corr': False, 'pra': False, 'peg': False, 'socorro!': False, 'roub': False, 'doces!': False, 'persegu': False, 'entr': False, 'lá,': False, 'perig': False, 'continu': False, 'assust': False, 'selv': False, 'animal': False, 'avanc': False, 'cautel': False, 'silenci': False, 'mais,': False, 'cuidado!': False, 'favor,': False, 'deixe-m': False, 'viver!': False, 'mes': False, 'tir': False, 'not': False, 'baix': False, 'parec': False, 'vigi': False, 'tem': False, 'sentenç': False, 'juiz': False, 'poss': False, 'nega': False, 'miss': False, 'arrisc': False, 'salvem-s': False, 'puder!': False, 'plan': False, 'descobert': False, 'culpa,': False, 'jur': False, 'tom': False, 'cuid': False, 'lobisom': False, 'achar,': False, 'descobr': False, 'verdad': False, 'deus,': False, 'desapareceu!': False, 'daqui!': False, 'mantenh': False, 'segredo,': False, 'est': False, 'ferr': False, 'soltem,': False, 'inoc': False, 'ouv': False, 'pass': False, 'atrás': False, 'ped': False, 'curv': False, 'estr': False, 'sei': False, 'não,': False, 'trem': False, 'medo!': False, 'socorro,': False, 'cair!': False, 'ate': False, 'florest': False, 'negra,': False, 'ouç': False, 'direç': False, 'voltar,': False, 'fuja,': False, 'acab': False, 'mort': False, 'recei': False, 'livr': False, 'dest': False, 'situ': False, 'armado!': False, 'ei': False, 'cuidado,': False, 'bat': False, 'poste!': False, 'afund': False, 'serio,': False, 'arma!': False, 'tub': False, 'atacando!': False, 'arrepi': False, 'so': False, 'escur': False, 'calma,': False, 'dinh': False, 'send': False, 'engan': False, 'ligeiro,': False, 'fug': False, 'depress': False, 'crocodil': False, 'vind': False, 'cá': False, 'quiet': False, 'vão': False, 'fuja!': False, 'tigr': False, 'famint': False, 'saída,': False, 'precis': False, 'milagr': False, 'mim!': False, 'nadar,': False, 'afogar!': False, 'apanh': False, 'pal': False, 'ver': False, 'boletim': False, 'consig': False, 'sair': False, 'tarde,': False, 'assalt': False, 'deix': False, 'favor!': False, 'espere,': False, 'larg': False, 'seguranç': False, 'entreg': False, 'dinheiro,': False, 'favor': False, 'mate!': False, 'lev': False, 'dirij': False, 'rápid': False, 'assim': False, 'descobriram,': False, 'irã': False, 'prender!': False, 'esper': False, 'nenhum': False, 'mal': False, 'afogar,': False, 'salv': False, 'pens': False, 'acontec': False, 'ness': False, 'cidad': False, 'desgr': False, 'algu': False, 'ligando,': False, 'remedio,': False, 'mat': False, 'confi': False, 'nele,': False, 'descoberto,': False, 'ir': False, 'estremec': False, 'cas': False, 'criat': False, 'mov': False, 'monstruos': False, 'agüent': False, 'suspens': False, 'afug': False, 'cão': False, 'choc': False, 'amedront': False, 'assassinat': False, 'brut': False, 'afugent': False, 'ímpet': False, 'med': False, 'infern': False, 'polít': False, 'us': False, 'forç': False, 'pov': False, 'obje': False, 'diss': False, 'apen': False, 'apav': False}\n"
     ]
    }
   ],
   "source": [
    "#--------------- Tratamento da Base de treinamento --------------------------\n",
    "#  junto com tratamento da palavras \n",
    "# importando ambas as bases \n",
    "df_teste = pd.read_excel(\"teste.xlsx\")\n",
    "df_treinamento = pd.read_excel(\"treinamento.xlsx\")\n",
    "df_teste\n",
    "\n",
    "# as stopwords são palavras que vão ser removidas das frases pois não tem relevância na classificação da frase em questão\n",
    "\n",
    "stopwords = ['a', 'agora', 'algum', 'alguma', 'aquele', 'aqueles', 'de', 'deu', 'do', 'e', 'estou', 'esta', 'esta',\n",
    "             'ir', 'meu', 'muito', 'mesmo', 'no', 'nossa', 'o', 'outro', 'para', 'que', 'sem', 'talvez', 'tem', 'tendo',\n",
    "             'tenha', 'teve', 'tive', 'todo', 'um', 'uma', 'umas', 'uns', 'vou']\n",
    "\n",
    "stopwordsnltk = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwordsnltk.append('vou')\n",
    "stopwordsnltk.append('tão')\n",
    "print(stopwordsnltk)\n",
    "\n",
    "# essa função remove as stopword previamente estabelecidads e retornar para uma lista, as palavras importantes e seu classificador. de treinamento.\n",
    "def removestopwords(texto):\n",
    "    frases = []\n",
    "    for (palavras, emocao) in texto:\n",
    "        semstop = [p for p in palavras.split() if p not in stopwordsnltk]\n",
    "        frases.append((semstop, emocao))\n",
    "    return frases\n",
    "\n",
    "\n",
    "\n",
    "# a função a seguir pega as palavras em questão e deixa apenas o seu radical removendo assim seus afixos  \n",
    "def aplicastemmer(texto, emocao):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    frasesstemming = []\n",
    "    for frase, emocao in zip(texto, emocao):\n",
    "        palavras = frase.split()\n",
    "        comstemming = [str(stemmer.stem(p)) for p in palavras if p not in stopwordsnltk]\n",
    "        frasesstemming.append((comstemming, emocao))\n",
    "    return frasesstemming\n",
    "\n",
    "\n",
    "frasescomstemmingteste = aplicastemmer(df_teste['texto'],df_teste['emoção'])\n",
    "frasescomstemmingtreinamento = aplicastemmer(df_treinamento['texto'],df_treinamento['emoção'])\n",
    "print(frasescomstemmingtreinamento)\n",
    "\n",
    "\n",
    "def buscapalavras(frases):\n",
    "    todaspalavras = []\n",
    "    for (palavras, emocao) in frases:\n",
    "        todaspalavras.extend(palavras)\n",
    "    return todaspalavras\n",
    "\n",
    "palavrastreinamento = buscapalavras(frasescomstemmingtreinamento)\n",
    "palavrasteste = buscapalavras(frasescomstemmingteste)\n",
    "print(palavrastreinamento)\n",
    "\n",
    "# essa função verifica a frequência a qual uma certa palavra acontece e retornar as palavras com maior frequência \n",
    "def buscafrequencia(palavras):\n",
    "    palavras = nltk.FreqDist(palavras)\n",
    "    return palavras\n",
    "\n",
    "frequenciatreinamento = buscafrequencia(palavrastreinamento)\n",
    "frequenciateste = buscafrequencia(palavrasteste)\n",
    "print(frequenciatreinamento.most_common(50))\n",
    "\n",
    "# essa função vai receber a frequencia e retornar as palavras sem nenhuma repetição \n",
    "def buscapalavrasunicas(frequencia):\n",
    "    freq = frequencia.keys()\n",
    "    return freq\n",
    "\n",
    "palavrasunicastreinamento = buscapalavrasunicas(frequenciatreinamento)\n",
    "palavrasunicasteste = buscapalavrasunicas(frequenciateste)\n",
    "#print(palavrasunicastreinamento)\n",
    "\n",
    "#print(palavrasunicastreinamento)\n",
    "\n",
    "# essa função vai verificar se cada palvra da frase em questão, está presente na base de palavras unicas gerada na função anterior  \n",
    "def extratorpalavras(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicas = {}\n",
    "    for palavras in palavrasunicastreinamento:\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\n",
    "    return caracteristicas\n",
    "\n",
    "caracteristicasfrase = extratorpalavras(['am', 'nov', 'dia'])\n",
    "print(caracteristicasfrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e88d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alegria', 'medo']\n",
      "Most Informative Features\n",
      "                     pod = True             medo : alegri =      4.0 : 1.0\n",
      "                     ach = True             medo : alegri =      3.1 : 1.0\n",
      "                    cert = True             medo : alegri =      3.1 : 1.0\n",
      "                     fic = True             medo : alegri =      3.1 : 1.0\n",
      "                     vai = True             medo : alegri =      3.1 : 1.0\n",
      "                    sint = True           alegri : medo   =      2.8 : 1.0\n",
      "                     vam = True           alegri : medo   =      2.3 : 1.0\n",
      "                    ajud = True             medo : alegri =      1.3 : 1.0\n",
      "                     aqu = True             medo : alegri =      1.3 : 1.0\n",
      "                     car = True             medo : alegri =      1.3 : 1.0\n",
      "                     deu = True             medo : alegri =      1.3 : 1.0\n",
      "                     faç = True             medo : alegri =      1.3 : 1.0\n",
      "                     lug = True             medo : alegri =      1.3 : 1.0\n",
      "                    muit = True             medo : alegri =      1.3 : 1.0\n",
      "                     olh = True             medo : alegri =      1.3 : 1.0\n",
      "                     vej = True             medo : alegri =      1.3 : 1.0\n",
      "                     águ = True             medo : alegri =      1.3 : 1.0\n",
      "                     mim = True           alegri : medo   =      1.3 : 1.0\n",
      "                    noit = True           alegri : medo   =      1.3 : 1.0\n",
      "                    outr = True           alegri : medo   =      1.3 : 1.0\n",
      "None\n",
      "0.7023809523809523\n",
      "        |  a    |\n",
      "        |  l    |\n",
      "        |  e    |\n",
      "        |  g  m |\n",
      "        |  r  e |\n",
      "        |  i  d |\n",
      "        |  a  o |\n",
      "--------+-------+\n",
      "alegria |<42> 6 |\n",
      "   medo | 19<17>|\n",
      "--------+-------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# analisando sua efetividade \n",
    "\n",
    "#--------------- Aplicação do Modelo --------------------------\n",
    "\n",
    "# pega os dados tratados e transformar eles numa base de dados de treinamento do modelo e na base de teste \n",
    "basecompletatreinamento = nltk.classify.apply_features(extratorpalavras, frasescomstemmingtreinamento)\n",
    "basecompletateste = nltk.classify.apply_features(extratorpalavras, frasescomstemmingteste)\n",
    "\n",
    "\n",
    "# constroi a tabela de probabilidade\n",
    "classificador = nltk.NaiveBayesClassifier.train(basecompletatreinamento)\n",
    "# verificando os classificadores \n",
    "\n",
    "print(classificador.labels())\n",
    "\n",
    "# mostra as caracteristicas de cada radical para os classificadores \n",
    "\n",
    "print(classificador.show_most_informative_features(20))\n",
    "\n",
    "# verificando a acuracia do modelo através da base de teste \n",
    "\n",
    "print(nltk.classify.accuracy(classificador, basecompletateste))\n",
    "\n",
    "erros = []\n",
    "for (frase, classe) in basecompletateste:\n",
    "    #print(frase)\n",
    "    #print(classe)\n",
    "    resultado = classificador.classify(frase)\n",
    "    if resultado != classe:\n",
    "        erros.append((classe, resultado, frase))\n",
    "#for (classe, resultado, frase) in erros:\n",
    "#    print(classe, resultado, frase)\n",
    "\n",
    "\n",
    "#matriz de confusão \n",
    "#Ela exibe a distribuição dos registros em termos de suas classes atuais e de suas classes previstas \n",
    "# Sendo uma métrica importante para validação do modelo e sua utilidade \n",
    "\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "esperado = []\n",
    "previsto = []\n",
    "for (frase, classe) in basecompletateste:\n",
    "    resultado = classificador.classify(frase)\n",
    "    previsto.append(resultado)\n",
    "    esperado.append(classe)\n",
    "\n",
    "#esperado = 'alegria alegria alegria alegria medo medo surpresa surpresa'.split()\n",
    "#previsto = 'alegria alegria medo surpresa medo medo medo surpresa'.split()\n",
    "matriz = ConfusionMatrix(esperado, previsto)\n",
    "print(matriz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5be9314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frases</th>\n",
       "      <th>Emoções</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A alegria evita mil males e prolonga a vida.</td>\n",
       "      <td>alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saber encontrar a alegria na alegria dos outro...</td>\n",
       "      <td>alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A alegria está na luta, na tentativa, no sofri...</td>\n",
       "      <td>alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A alegria de fazer o bem é a única felicidade ...</td>\n",
       "      <td>alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eu vou te matar seu maldito bastardo!</td>\n",
       "      <td>medo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nada que um beijo da boa e velha Morte</td>\n",
       "      <td>medo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Frases  Emoções\n",
       "0       A alegria evita mil males e prolonga a vida.  alegria\n",
       "1  Saber encontrar a alegria na alegria dos outro...  alegria\n",
       "2  A alegria está na luta, na tentativa, no sofri...  alegria\n",
       "3  A alegria de fazer o bem é a única felicidade ...  alegria\n",
       "4              Eu vou te matar seu maldito bastardo!     medo\n",
       "5            Nada que um beijo da boa e velha Morte      medo"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------- Utilização do modelo --------------------------\n",
    "# é lida uma planilha para classificação \n",
    "df_classifica = pd.read_excel(\"Classificaveis.xlsx\")\n",
    "\n",
    "# essa função é criado o classificador de frases que fui testado no modelo acima \n",
    "\n",
    "def classificado(frase):\n",
    "    testestemming = []\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    for (palavras) in frase.split():\n",
    "        comstem = [p for p in palavras.split()]\n",
    "        testestemming.append(str(stemmer.stem(comstem[0])))\n",
    "    novo = extratorpalavras(testestemming)\n",
    "    return classificador.classify(novo)\n",
    "\n",
    "df_classifica['Emoções'] = df_classifica['Frases'].apply(classificado)\n",
    "df_classifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d8bf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
